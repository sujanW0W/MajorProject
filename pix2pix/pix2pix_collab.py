# -*- coding: utf-8 -*-
"""pix2pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zgPMO0TadtdPp762Q9-8YlbPAcTQT2TL
"""

"""Imports"""

from os import makedirs
from os import listdir
from numpy import load
from numpy import zeros
from numpy import ones
from numpy import savetxt
from numpy.random import randint
from numpy.lib.npyio import NpzFile
from numpy import asarray
from numpy import vstack
from numpy import savez_compressed
import tensorflow
from tensorflow.keras.optimizers import Adam
from scipy.sparse import load_npz
from keras.models import load_model
from keras.initializers import RandomNormal
from keras.models import Model
from keras import Input
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU
from keras.layers import Activation
from keras.layers import Concatenate
from keras.layers import Dropout
from keras.layers import BatchNormalization
from keras.layers import LeakyReLU
from keras.utils import img_to_array
from keras.utils import load_img
from matplotlib import pyplot

"""Discriminator"""

def define_discriminator(image_shape):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# source image input
	in_src_image = Input(shape=image_shape)
	# target image input
	in_target_image = Input(shape=image_shape)
	# concatenate images channel-wise
	merged = Concatenate()([in_src_image, in_target_image])
	# C64
	d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)
	d = LeakyReLU(alpha=0.2)(d)
	# C128
	d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = BatchNormalization()(d)
	d = LeakyReLU(alpha=0.2)(d)
	# C256
	d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = BatchNormalization()(d)
	d = LeakyReLU(alpha=0.2)(d)
	# C512
	d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = BatchNormalization()(d)
	d = LeakyReLU(alpha=0.2)(d)
	# second last output layer
	d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)
	d = BatchNormalization()(d)
	d = LeakyReLU(alpha=0.2)(d)
	# patch output
	d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)
	patch_out = Activation('sigmoid')(d)
	# define model
	model = Model([in_src_image, in_target_image], patch_out)
	# compile model
	opt = tensorflow.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5], metrics=['accuracy']) # [tf.keras.metrics.BinaryAccuracy()]
	return model

"""Encoder block"""

def define_encoder_block(layer_in, n_filters, batchnorm=True):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# add downsampling layer
	g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
	# conditionally add batch normalization
	if batchnorm:
		g = BatchNormalization()(g, training=True)
	# leaky relu activation
	g = LeakyReLU(alpha=0.2)(g)
	return g

"""Decoder block"""

def decoder_block(layer_in, skip_in, n_filters, dropout=True):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# add upsampling layer
	g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
	# add batch normalization
	g = BatchNormalization()(g, training=True)
	# conditionally add dropout
	if dropout:
		g = Dropout(0.5)(g, training=True)
	# merge with skip connection
	g = Concatenate()([g, skip_in])
	# relu activation
	g = Activation('relu')(g)
	return g

"""Generator"""

def define_generator(image_shape=(256,256,3)):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# image input
	in_image = Input(shape=image_shape)
	# encoder model
	e1 = define_encoder_block(in_image, 64, batchnorm=False)
	e2 = define_encoder_block(e1, 128)
	e3 = define_encoder_block(e2, 256)
	e4 = define_encoder_block(e3, 512)
	e5 = define_encoder_block(e4, 512)
	e6 = define_encoder_block(e5, 512)
	e7 = define_encoder_block(e6, 512)
	# bottleneck, no batch norm and relu
	b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)
	b = Activation('relu')(b)
	# decoder model
	d1 = decoder_block(b, e7, 512)
	d2 = decoder_block(d1, e6, 512)
	d3 = decoder_block(d2, e5, 512)
	d4 = decoder_block(d3, e4, 512, dropout=False)
	d5 = decoder_block(d4, e3, 256, dropout=False)
	d6 = decoder_block(d5, e2, 128, dropout=False)
	d7 = decoder_block(d6, e1, 64, dropout=False)
	# output
	g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)
	out_image = Activation('tanh')(g)
	# define model
	model = Model(in_image, out_image)
	return model

"""GAN model"""

def define_gan(g_model, d_model, image_shape):
	# make weights in the discriminator not trainable
	for layer in d_model.layers:
		if not isinstance(layer, BatchNormalization):
			layer.trainable = False
	# define the source image
	in_src = Input(shape=image_shape)
	# connect the source image to the generator input
	gen_out = g_model(in_src)
	# connect the source input and generator output to the discriminator input
	dis_out = d_model([in_src, gen_out])
	# src image as input, generated image and classification output
	model = Model(in_src, [dis_out, gen_out])
	# compile model
	opt = tensorflow.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100], metrics=['accuracy'])
	return model

"""Load real samples"""

def load_real_samples(filename):
	# load compressed arrays
	data = load(filename)
	# unpack arrays
	X2, X1 = data['arr_0'], data['arr_1'] # source = X2, destination = X1
	# scale from [0,255] to [-1,1]
	X1 = (X1 - 127.5) / 127.5
	X2 = (X2 - 127.5) / 127.5
	return [X1, X2]

"""Generate real samples"""

def generate_real_samples(dataset, n_samples, patch_shape):
	# unpack dataset
	trainA, trainB = dataset
	# choose random instances
	ix = randint(0, trainA.shape[0], n_samples)
	# retrieve selected images
	X1, X2 = trainA[ix], trainB[ix]
	# generate 'real' class labels (1)
	y = ones((n_samples, patch_shape, patch_shape, 1))
	return [X1, X2], y

"""Generate fake samples"""

def generate_fake_samples(g_model, samples, patch_shape):
	# generate fake instance
	X = g_model.predict(samples)
	# create 'fake' class labels (0)
	y = zeros((len(X), patch_shape, patch_shape, 1))
	return X, y

"""Summarize performance"""

def summarize_performance(step, g_model, dataset, n_samples=3):
	# select a sample of input images
	[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)
	# generate a batch of fake samples
	X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)
	# scale all pixels from [-1,1] to [0,1]
	X_realA = (X_realA + 1) / 2.0
	X_realB = (X_realB + 1) / 2.0
	X_fakeB = (X_fakeB + 1) / 2.0
	# plot real source images
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + i)
		pyplot.axis('off')
		pyplot.imshow(X_realA[i])
	# plot generated target image
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + n_samples + i)
		pyplot.axis('off')
		pyplot.imshow(X_fakeB[i])
	# plot real target image
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)
		pyplot.axis('off')
		pyplot.imshow(X_realB[i])
	# save plot to file
	filename1 = 'outputs/plots/plot_%06d.png' % (step+1)
	pyplot.savefig(filename1)
	pyplot.close()
	# save the generator model
	filename2 = 'outputs/models/model_%06d' % (step+1) # removed .h5
	g_model.save(filename2, save_format = "tf") # added save_format
	print('>Saved: %s and %s' % (filename1, filename2))

"""Plot loss function"""

# create a line plot of loss for the gan and save to file
def plot_history(step, d1_hist_avg, d2_hist_avg, g_hist_avg, a1_hist_avg, a2_hist_avg):
	# plot discriminator loss
	pyplot.plot(d1_hist_avg, label='d-real')
	pyplot.plot(d2_hist_avg, label='d-fake')
	pyplot.legend()
	filename1 = 'outputs/dis_loss/plot_discriminator_loss_%06d.png' % (step+1)
	pyplot.savefig(filename1)
	pyplot.close()

	# plot generator loss
	pyplot.plot(g_hist_avg, label='gen')
	pyplot.legend()
	filename2 = 'outputs/gen_loss/plot_generator_loss_%06d.png' % (step+1)
	pyplot.savefig(filename2)
	pyplot.close()

  	# plot discriminator accuracy
	pyplot.plot(a1_hist_avg, label='acc-real')
	pyplot.plot(a2_hist_avg, label='acc-fake')
	pyplot.legend()
	filename3 = 'outputs/dis_acc/plot_discriminator_accuracy_%06d.png' % (step+1)
	pyplot.savefig(filename3)
	pyplot.close()

"""Train model"""

def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=4):
	# determine the output square shape of the discriminator
	n_patch = d_model.output_shape[1]
	# unpack dataset
	trainA, trainB = dataset
	# calculate the number of batches per training epoch
	bat_per_epo = int(len(trainA) / n_batch)
	# calculate the number of training iterations
	n_steps = bat_per_epo * n_epochs
	# prepare lists for storing stats each iteration
	d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()

	# manually enumerate epochs
	for i in range(n_steps):
		# select a batch of real samples
		[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)
		# generate a batch of fake samples
		X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)
		# update discriminator for real samples
		d_loss1, d_acc1 = d_model.train_on_batch([X_realA, X_realB], y_real)
		d_loss2, d_acc2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)
		# update the generator
		g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])
		# summarize performance
		print('>%d, d1[%.3f] d2[%.3f] g[%.3f], a1=[%d], a2=[%d]' % (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))
		
		# record history
		d1_hist.append(d_loss1)
		d2_hist.append(d_loss2)
		g_hist.append(g_loss)
		a1_hist.append(d_acc1)
		a2_hist.append(d_acc2)
	 
		# store histories and plot graphs
		if (i+1) % (bat_per_epo) == 0:
			
			# calculate average of histories
			d1_hist_avg = sum(d1_hist)/len(d1_hist)
			d2_hist_avg = sum(d2_hist)/len(d2_hist)
			g_hist_avg = sum(g_hist)/len(g_hist)
			a1_hist_avg = sum(a1_hist)/len(a1_hist)
			a2_hist_avg = sum(a2_hist)/len(a2_hist)

			# append averages to list
			d1_hist_avg_list.append(d1_hist_avg)
			d2_hist_avg_list.append(d2_hist_avg)
			g_hist_avg_list.append(g_hist_avg)
			a1_hist_avg_list.append(a1_hist_avg)
			a2_hist_avg_list.append(a2_hist_avg)
	 
			d1_hist.clear()
			d2_hist.clear()
			g_hist.clear()
			a1_hist.clear()
			a2_hist.clear()
	 
			plot_history(i, d1_hist_avg_list, d2_hist_avg_list, g_hist_avg_list, a1_hist_avg_list, a2_hist_avg_list)

	# summarize model performance	 
		if (i+1) % (bat_per_epo * 10) == 0:
		 	summarize_performance(i, g_model, dataset)

"""Main"""

# load image data
dataset = load_real_samples('/content/gdrive/My Drive/streetview_256.npz')
print('Loaded', dataset[0].shape, dataset[1].shape)

# make folder for results
makedirs('outputs', exist_ok=True)
makedirs('outputs//plots', exist_ok=True)
makedirs('outputs/models', exist_ok=True)
makedirs('outputs/dis_acc', exist_ok=True)
makedirs('outputs/dis_loss', exist_ok=True)
makedirs('outputs/gen_loss', exist_ok=True)

d1_hist_avg_list, d2_hist_avg_list, g_hist_avg_list, a1_hist_avg_list, a2_hist_avg_list = list(), list(), list(), list(), list()

# define input shape based on the loaded dataset
image_shape = dataset[0].shape[1:]

# define the models
d_model = define_discriminator(image_shape)
g_model = define_generator(image_shape)
# g_model = load_model(/output/models/model_006250/')

# define the composite model
gan_model = define_gan(g_model, d_model, image_shape)
gan_model.compile(loss=['binary_crossentropy', 'mae'], optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[1,100])

# train model
train(d_model, g_model, gan_model, dataset)

# data rows of csv file 
rows = [ d1_hist_avg_list, 
         d2_hist_avg_list, 
         g_hist_avg_list, 
         a1_hist_avg_list, 
         a2_hist_avg_list] 
  
# using the savetxt from numpy module
savetxt("outputs/histories.csv", rows, delimiter =", ", fmt ='% s')